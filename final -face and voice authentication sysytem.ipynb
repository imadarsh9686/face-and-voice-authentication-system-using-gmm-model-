{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47a9202",
   "metadata": {},
   "source": [
    "# VOICE AND FACE AUTHENTICATION SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba122a0",
   "metadata": {},
   "source": [
    "### RUN THE CELL ONE BY ONE AFTER READING INSTRUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c51a4",
   "metadata": {},
   "source": [
    "## Please install necessary library required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea9fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "import pyaudio\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "#from sklearn.mixture import GMM \n",
    "from sklearn.mixture import GaussianMixture \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e29a2",
   "metadata": {},
   "source": [
    "# Audio processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b696c",
   "metadata": {},
   "source": [
    "### -After installling all the necessary library pls run the below cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd80cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "    rows, cols = array.shape\n",
    "    deltas = np.zeros((rows, cols))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while len(index) < 2 and j < N+1:\n",
    "            if i-j >= 0:\n",
    "                index.append(i-j)\n",
    "            if i+j < rows:\n",
    "                index.append(i+j)\n",
    "            j+=1\n",
    "        if len(index) == 2:\n",
    "            deltas[i] = (array[index[1]] - array[index[0]]) / (2*N)\n",
    "        elif len(index) == 1:\n",
    "            deltas[i] = (array[index[0]] - array[i]) / N\n",
    "    return deltas\n",
    "\n",
    "\n",
    "#convert audio to mfcc features\n",
    "def extract_features(audio, rate):    \n",
    "    mfcc_feat = mfcc.mfcc(audio, rate, 0.025, 0.01, 12, appendEnergy=True, nfft=2048)\n",
    "    mfcc_feat = preprocessing.scale(mfcc_feat)\n",
    "    delta = calculate_delta(mfcc_feat)\n",
    "\n",
    "    #combining both mfcc features and delta\n",
    "    combined = np.hstack((mfcc_feat, delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4a399",
   "metadata": {},
   "source": [
    "# Registering  New User voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3e681",
   "metadata": {},
   "source": [
    "### Run the below code for registering new voice of the person .\n",
    "\n",
    "### WARNING:- RECORD IN SILENCE\n",
    "\n",
    "\n",
    "##### -------------------- follow steps below --------------------------------------------\n",
    "\n",
    "#### - RUN THE CODE \n",
    "#### - ENTER  YOUR NAME \n",
    "#### - SPEAK HELLO COMPUTER WHEN RECORDING\n",
    "#### - SPEAK SAME WORD 2 TIMES MORE\n",
    "#### - NOW YOUR VOICE REGISTERED \n",
    "\n",
    "#### - REGISTER THE 2 OR 3 PERSON VOICE \n",
    "#### - NOW YOUR VOICE REGISTERED \n",
    "\n",
    "###### -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## TIPS:- register silence, noise  as name- unknown to classify as unknown\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdee8266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "Done\n",
      "Speak your name one more time\n",
      "recording...\n",
      "Done\n",
      "Speak your name one last time\n",
      "recording...\n",
      "Done\n",
      "unknown3 added successfully\n"
     ]
    }
   ],
   "source": [
    "name=input(\"Enter your name: \")\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 3\n",
    "\n",
    "\n",
    "source = \"./voice_database/\" + name\n",
    "\n",
    "os.mkdir(source)\n",
    "\n",
    "for i in range(3):\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    if i == 0:\n",
    "        j = 3\n",
    "        while j>=0:\n",
    "            time.sleep(1.0)\n",
    "            print(\"Speak your name in {} seconds\".format(j))\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            j-=1\n",
    "\n",
    "    elif i == 1:\n",
    "        print(\"Speak your name one more time\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    else:\n",
    "        print(\"Speak your name one last time\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # saving wav file of speaker\n",
    "    waveFile = wave.open(source + '/' + str((i+1)) + '.wav', 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "    print(\"Done\")\n",
    "\n",
    "dest = \"./gmm_models/\"\n",
    "count = 1\n",
    "\n",
    "for path in os.listdir(source):\n",
    "    path = os.path.join(source, path)\n",
    "\n",
    "    features = np.array([])\n",
    "\n",
    "    # reading audio files of speaker\n",
    "    (sr, audio) = read(path)\n",
    "\n",
    "    # extract 40 dimensional MFCC & delta MFCC features\n",
    "    vector = extract_features(audio, sr)\n",
    "\n",
    "    if features.size == 0:\n",
    "        features = vector\n",
    "    else:\n",
    "        features = np.vstack((features, vector))\n",
    "\n",
    "    # when features of 3 files of speaker are concatenated, then do model training\n",
    "    if count == 3:\n",
    "        gmm = GaussianMixture(n_components=16, max_iter=200, covariance_type='diag', n_init=3)\n",
    "        gmm.fit(features)\n",
    "\n",
    "        # saving the trained gaussian model\n",
    "        #pickle.dump(gmm, open(dest + name + '.gmm', 'wb'))\n",
    "        # save trained model\n",
    "        \n",
    "        #pickle.dump(gmm, open(dest + name + '.gmm', 'wb'))\n",
    "        \n",
    "        \n",
    "        with open(dest + name + '.pkl', 'wb') as file:\n",
    "            pickle.dump(gmm, file)\n",
    "        print(name + ' added successfully')\n",
    "\n",
    "        features = np.asarray(())\n",
    "        count = 0\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99a395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de9fe487",
   "metadata": {},
   "source": [
    "# Registering a New User face "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6fda7",
   "metadata": {},
   "source": [
    "###  Run the below code for registering new face of the person .\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### --------------------------------------------------------follow steps below--------------------------------------------------------------------------------------- \n",
    "\n",
    "#### - RUN THE CODE \n",
    "#### - ENTER  YOUR NAME \n",
    "#### - IT START RECORDING \n",
    "#### - PRESS S TO SAVE IMAGE \n",
    "#### - AFTER THE MESSAGE SUCCESSFUL PRINTED IN BELOW CELL\n",
    "#### - PRESS Q TO EXIT\n",
    " \n",
    "#### --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## TIPS:- register 2 to 3 image to help the model to classify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Create a directory to store captured images\n",
    "dir_name = 'captured_images'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "# Get name of the person to capture images\n",
    "name = input(\"Enter your name: \")\n",
    "\n",
    "# Create a directory with the name of the person\n",
    "person_dir = os.path.join(dir_name, name)\n",
    "if not os.path.exists(person_dir):\n",
    "    os.makedirs(person_dir)\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the width and height of the capture window\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "# Capture frames continuously\n",
    "while True:\n",
    "    # Capture a frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display instructions in the frame\n",
    "    cv2.putText(frame, \"Press 'q' to exit\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Press 's' to save image\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Exit the camera if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Save the image if 's' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        # Generate a unique filename for the image\n",
    "        filename = os.path.join(person_dir, name + \"_\" + str(len(os.listdir(person_dir))+1) + \".jpg\")\n",
    "\n",
    "        # Save the image\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(\"Image saved successfully!\")\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401325d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd73a13f",
   "metadata": {},
   "source": [
    "# Automatically add array of face encodings and there name and store it in a empty list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50ab82",
   "metadata": {},
   "source": [
    "### just run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62dee765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known face encodings: [array([-0.10603727,  0.13406637,  0.09755316,  0.01717214, -0.0177455 ,\n",
      "       -0.0443629 , -0.06481581, -0.03275372,  0.08441459,  0.01632946,\n",
      "        0.23954946, -0.08707264, -0.25597417, -0.14971158, -0.0085438 ,\n",
      "        0.11727355, -0.05354901, -0.17429779, -0.05566221, -0.06684638,\n",
      "        0.01994321,  0.03799533,  0.04113675,  0.00206695, -0.08606327,\n",
      "       -0.44688386, -0.03061007, -0.111617  ,  0.09729519, -0.06653468,\n",
      "       -0.03572546,  0.00345196, -0.21564899, -0.05102433,  0.03085935,\n",
      "        0.11574043, -0.04740578, -0.02374438,  0.18887484,  0.0093974 ,\n",
      "       -0.1249586 , -0.02845469,  0.06041468,  0.26397482,  0.1454096 ,\n",
      "        0.0742325 ,  0.04354211, -0.04550374, -0.01831933, -0.19970518,\n",
      "        0.09574576,  0.15648206,  0.13781491,  0.05862052,  0.15629384,\n",
      "       -0.13437159,  0.00889811,  0.08292488, -0.22097458,  0.05514112,\n",
      "       -0.01189425,  0.01842091, -0.05770644, -0.05067457,  0.27391085,\n",
      "        0.0429178 , -0.0594479 , -0.13464162,  0.16123369, -0.13305581,\n",
      "       -0.00178956,  0.14113933, -0.01813134, -0.13613704, -0.22132431,\n",
      "        0.09642544,  0.34997931,  0.12127701, -0.22568212,  0.06851634,\n",
      "       -0.07803802, -0.10396923,  0.06707836, -0.07595757, -0.08291728,\n",
      "       -0.00289785, -0.18761013, -0.03399368,  0.16938767, -0.00395687,\n",
      "       -0.00139513,  0.13721819, -0.01607521,  0.0188137 ,  0.05488146,\n",
      "        0.00336016, -0.14316252,  0.02044675, -0.14225027, -0.13444062,\n",
      "        0.07828967, -0.0775308 , -0.03264317,  0.03481954, -0.16887785,\n",
      "        0.06280778,  0.0304071 , -0.0749515 ,  0.01111858,  0.04733396,\n",
      "       -0.12045571, -0.07340106,  0.14692143, -0.30016467,  0.21811636,\n",
      "        0.13008945,  0.03443435,  0.13372569,  0.10088558,  0.04247914,\n",
      "        0.00368936, -0.06912599, -0.1101189 , -0.10351849,  0.02299741,\n",
      "       -0.02239469,  0.03711545,  0.05326903]), array([-0.11570382,  0.05667396,  0.01546982, -0.05929952, -0.06373566,\n",
      "       -0.05947407,  0.000724  , -0.0886644 ,  0.24590169, -0.07706074,\n",
      "        0.25404254, -0.03247483, -0.21874547, -0.0541866 , -0.06762022,\n",
      "        0.11415937, -0.05892004, -0.13333409,  0.00922704, -0.13368487,\n",
      "        0.01352257,  0.00333115,  0.0067419 ,  0.07553408, -0.08386825,\n",
      "       -0.36416787, -0.12299661, -0.16484462,  0.06705251, -0.14402677,\n",
      "        0.02264579,  0.10297156, -0.15805392, -0.07981529,  0.0333809 ,\n",
      "        0.05543875, -0.00388106, -0.01584346,  0.19816001,  0.03422074,\n",
      "       -0.09935042, -0.05226136,  0.07151347,  0.32679009,  0.04266211,\n",
      "        0.06008144,  0.04400277, -0.08088581,  0.08726948, -0.12261187,\n",
      "        0.13194744,  0.09725229,  0.10399802,  0.02685994,  0.06983612,\n",
      "       -0.15660754,  0.02015711,  0.04655216, -0.30710381,  0.14173946,\n",
      "        0.12412062, -0.00147888, -0.14983431, -0.00702657,  0.22111703,\n",
      "        0.14975272, -0.1073231 , -0.13973323,  0.16116571, -0.19004115,\n",
      "        0.03944447,  0.06977563, -0.11224101, -0.16990721, -0.18131863,\n",
      "        0.09933697,  0.42087975,  0.12943847, -0.09298892,  0.03701171,\n",
      "       -0.06210217, -0.07024469,  0.04512344,  0.02040205, -0.12600783,\n",
      "        0.03107351, -0.07976993,  0.0450194 ,  0.10747006,  0.05971207,\n",
      "       -0.04674766,  0.18214631, -0.05166969,  0.0076165 ,  0.02519155,\n",
      "        0.08186058, -0.17950508, -0.02064397, -0.11814357, -0.09275647,\n",
      "        0.02812326, -0.08556145,  0.0058549 ,  0.05164061, -0.17794673,\n",
      "        0.12618467, -0.00547077, -0.04012119, -0.0318559 ,  0.10150631,\n",
      "       -0.12737398, -0.10268273,  0.12969001, -0.21876447,  0.15764613,\n",
      "        0.09440665,  0.09228863,  0.15991834,  0.06108769,  0.06263527,\n",
      "        0.036334  , -0.07320058, -0.10477547, -0.05269931,  0.00963878,\n",
      "       -0.01610888,  0.06338626,  0.00689716])]\n",
      "Known face names: ['adarsh', 'karthik']\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty arrays to store the face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "path = \"captured_images\"\n",
    "\n",
    "# Set the path to the folder containing the images of the particular person\n",
    "for file in os.listdir(path):\n",
    "    \n",
    "    person_path = os.path.join(path, file)\n",
    "    \n",
    "    # Get the list of image files in the folder\n",
    "    image_files = os.listdir(person_path)\n",
    "\n",
    "    # Check if there is at least one image file in the folder\n",
    "    if len(image_files) > 0:\n",
    "        # Select the first image file in the folder\n",
    "        image_file = image_files[0]\n",
    "    \n",
    "        # Load the image file\n",
    "        image = face_recognition.load_image_file(os.path.join(person_path, image_file))\n",
    "    \n",
    "        # Extract the face encoding from the image\n",
    "        encoding = face_recognition.face_encodings(image)[0]\n",
    "    \n",
    "        # Extract the name of the person from the filename\n",
    "        name = os.path.splitext(file)[0]\n",
    "    \n",
    "        # Append the face encoding and name to their respective arrays\n",
    "        known_face_encodings.append(encoding)\n",
    "        known_face_names.append(name)\n",
    "\n",
    "# Print the arrays of known face encodings and their names\n",
    "print(\"Known face encodings:\", known_face_encodings)\n",
    "print(\"Known face names:\", known_face_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4e457",
   "metadata": {},
   "source": [
    "# ----------------------------VOICE RECOGNITION---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff2538",
   "metadata": {},
   "source": [
    "### - JUST SPEAK SAME WORD YOU REGISTERED IN SAME PITCH TO RECOGNISE YOUR VOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d442f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording... say hello computer for authentication\n",
      "finished recording\n",
      "Recognized as -  adarsh\n",
      "adarsh\n"
     ]
    }
   ],
   "source": [
    "global identity\n",
    "\n",
    "def recognize_voice():\n",
    "    global identity\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 3\n",
    "    FILENAME = \"./test.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"recording... say hello computer for authentication\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # saving wav file \n",
    "    waveFile = wave.open(FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "    modelpath = \"./gmm_models/\"\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in os.listdir(modelpath) if fname.endswith('.pkl')]\n",
    "\n",
    "    models = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "\n",
    "    speakers = [fname.split(\"/\")[-1].split(\".pkl\")[0] for fname in gmm_files]\n",
    "\n",
    "    if len(models) == 0:\n",
    "        print(\"No Users in the Database!\")\n",
    "    \n",
    "    # read test file\n",
    "    sr, audio = read(FILENAME)\n",
    "\n",
    "    # extract mfcc features\n",
    "    vector = extract_features(audio, sr)\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "\n",
    "    # checking with each model one by one\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]\n",
    "        scores = np.array(gmm.score(vector[:,:40]))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    pred = np.argmax(log_likelihood)\n",
    "    identity = speakers[pred]\n",
    "\n",
    "    # if voice not recognized than terminate the process\n",
    "    if identity == 'unknown':\n",
    "        print(\"Not Recognized! Try again...\")\n",
    "        return\n",
    "\n",
    "    print(\"Recognized as - \", identity)\n",
    "    \n",
    "    return identity\n",
    "\n",
    "\n",
    "# example usage\n",
    "recognize_voice()\n",
    "print(identity)\n",
    "\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67863fd",
   "metadata": {},
   "source": [
    "# ----------------------------FACE AND VOICE AUTHENTICATION--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805fe25",
   "metadata": {},
   "source": [
    "#### - KEEP YOUR FACE INFRONT OF THE CAMERA\n",
    "### -------------------------------------THE RESULT WILL SHOW AS BELOW-----------------------------------\n",
    "#### - IF FACE MATCHES WITH VOICE  --Authenticaation successful !welcome-------\n",
    "#### - IF VOICE IDENTITY AND FACE IDENTIY IS DIFFERENT -----Voice identity not matching with face !Try again....\n",
    "#### - IF VOICE IDENTITY== UKNOWN     ------------Voice not recognized , !Try again.....\n",
    "#### - IF FACE IDENTITY == UKNOWN      -------------\" Face not registered,! Unsuccessful\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7dc52235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep Your face infront of the camera\n"
     ]
    }
   ],
   "source": [
    "#FACE RECOGNITION\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True    \n",
    "\n",
    "print(\"Keep Your face infront of the camera\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "    \n",
    "    \n",
    "time.sleep(1.0)\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    curr_time = time.time()\n",
    "            \n",
    "    _, frame = cap.read()\n",
    "        \n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        \n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "    face=face_recognition.face_locations(rgb_small_frame)\n",
    "        \n",
    "    if len(face) == 1:\n",
    "            \n",
    "        if process_this_frame:\n",
    "                \n",
    "            # Find all the faces and face encodings in the current frame of video\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "                \n",
    "            face_name = []\n",
    "                \n",
    "            for face_encoding in face_encodings:\n",
    "                    \n",
    "                # See if the face is a match for the known face(s)\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                facename=\"Unknown\"\n",
    "                    # # If a match was found in known_face_encodings, just use the first one.\n",
    "                    #if True in matches:\n",
    "                    #first_match_index = matches.index(True)\n",
    "                    #name = known_face_names[first_match_index]\n",
    "                    # Or instead, use the known face with the smallest distance to the new face\n",
    "                    \n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "            \n",
    "                if matches[best_match_index]:\n",
    "                    facename = known_face_names[best_match_index]\n",
    "                    face_names.append(facename)\n",
    "                            \n",
    "                 # if min dist is less then threshold value \n",
    "                 # and both face and voice matched than unlock the door\n",
    "                \n",
    "        process_this_frame = not process_this_frame\n",
    "        # Display the results\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "              # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 0), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            \n",
    "            if facename == identity: \n",
    "                cv2.putText(frame, facename +\" Authenticaation successful !welcome\", (left + 6, bottom - 6), font, 0.5, (0, 255, 0), 1)\n",
    "            elif facename==\"Unknown\":\n",
    "                cv2.putText(frame, facename+\" Face not registered,! Unsuccessful\", (left + 6, bottom - 6), font, 0.5, (0, 0, 255), 1)\n",
    "            elif identity==\"unknown\":\n",
    "                cv2.putText(frame, facename+\" Voice not recognized , !Try again.....\", (left + 6, bottom - 6), font, 0.5, (0, 0, 255), 1)\n",
    "            else: \n",
    "                cv2.putText(frame, facename+\" Voice identity not matching with face !Try again....\", (left + 6, bottom - 6), font, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release handle to the webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if len(face) == 0:\n",
    "    print('There was no face found in the frame. Try again...')\n",
    "                \n",
    "\n",
    "elif len(face) > 1:\n",
    "    print(\"More than one faces found. Try again...\")\n",
    "\n",
    "\n",
    "\n",
    "               \n",
    "\n",
    "\n",
    "                   \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71047a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
